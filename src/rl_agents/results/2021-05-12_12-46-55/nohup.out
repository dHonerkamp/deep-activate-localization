2021-05-12 12:46:55.190860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
WARNING:root:Argument blacklist is deprecated. Please use denylist.
WARNING:root:Argument blacklist is deprecated. Please use denylist.
INFO:root:Importing iGibson (gibson2 module)
INFO:root:Assets path: /home/guttikon/activate-localization/igibson/gibson2/data/assets
INFO:root:Gibson Dataset path: /home/guttikon/activate-localization/igibson/gibson2/data/g_dataset
INFO:root:iG Dataset path: /home/guttikon/activate-localization/igibson/gibson2/data/ig_dataset
INFO:root:3D-FRONT Dataset path: /home/guttikon/activate-localization/igibson/gibson2/data/threedfront_dataset
INFO:root:CubiCasa5K Dataset path: /home/guttikon/activate-localization/igibson/gibson2/data/cubicasa_dataset
INFO:root:Example path: /home/guttikon/activate-localization/igibson/gibson2/examples
INFO:root:Example config path: /home/guttikon/activate-localization/igibson/gibson2/examples/configs
pybullet build time: May  2 2021 09:44:36
2021-05-12 12:47:08.943679: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 12:47:08.944815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-12 12:47:08.988808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:08.989568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2021-05-12 12:47:08.989626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:08.990343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-05-12 12:47:08.990360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 12:47:08.996213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 12:47:08.996260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-12 12:47:08.998540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-12 12:47:09.000091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-12 12:47:09.004125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-12 12:47:09.006138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-12 12:47:09.007050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-12 12:47:09.007145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.007948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.008706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.009473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.010196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-05-12 12:47:09.010470: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-12 12:47:09.010664: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 12:47:09.142107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.142541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 447.48GiB/s
2021-05-12 12:47:09.142600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.143032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2021-05-12 12:47:09.143048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 12:47:09.143071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 12:47:09.143082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-12 12:47:09.143092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-12 12:47:09.143102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-12 12:47:09.143112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-12 12:47:09.143122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-12 12:47:09.143132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-12 12:47:09.143173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.143599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.144021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.144441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.144832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-05-12 12:47:09.144854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 12:47:09.795660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-12 12:47:09.795690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2021-05-12 12:47:09.795696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y 
2021-05-12 12:47:09.795700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N 
2021-05-12 12:47:09.795887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.796354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.796787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.797213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.797620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11010 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-05-12 12:47:09.798047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.798493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-05-12 12:47:09.798900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11226 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)
I0512 12:47:10.206434 140364252047168 get_available_devices.py:31] Device 0 is available for rendering
I0512 12:47:10.297499 140364252047168 get_available_devices.py:31] Device 1 is available for rendering
I0512 12:47:10.341895 140364252047168 get_available_devices.py:33] Command '['/home/guttikon/activate-localization/igibson/gibson2/render/mesh_renderer/build/test_device', '2']' returned non-zero exit status 1.
I0512 12:47:10.342213 140364252047168 get_available_devices.py:34] Device 2 is not available for rendering
I0512 12:47:10.381427 140364252047168 get_available_devices.py:33] Command '['/home/guttikon/activate-localization/igibson/gibson2/render/mesh_renderer/build/test_device', '3']' returned non-zero exit status 1.
I0512 12:47:10.381684 140364252047168 get_available_devices.py:34] Device 3 is not available for rendering
I0512 12:47:10.449477 140364252047168 mesh_renderer_cpu.py:87] Using device 0 for rendering
W0512 12:47:10.614193 140364252047168 mesh_renderer_cpu.py:228] Environment texture not available, cannot use PBR.
I0512 12:47:10.643418 140364252047168 indoor_scene.py:45] IndoorScene model: Rs
I0512 12:47:10.643580 140364252047168 gibson_indoor_scene.py:54] StaticIndoorScene scene: Rs
I0512 12:47:15.150784 140364252047168 indoor_scene.py:118] Loading traversable graph
I0512 12:47:15.157836 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/g_dataset/Rs/mesh_z_up.obj
/home/guttikon/activate-localization/igibson/gibson2/render/mesh_renderer/mesh_renderer_cpu.py:464: RuntimeWarning: divide by zero encountered in true_divide
  delta_uv1[:, 1] * delta_uv2[:, 0])
/home/guttikon/activate-localization/igibson/gibson2/render/mesh_renderer/mesh_renderer_cpu.py:466: RuntimeWarning: invalid value encountered in multiply
  delta_pos2 * delta_uv1[:, 1][:, None]) * r[:, None]
/home/guttikon/activate-localization/igibson/gibson2/render/mesh_renderer/mesh_renderer_cpu.py:468: RuntimeWarning: invalid value encountered in multiply
  delta_pos1 * delta_uv2[:, 0][:, None]) * r[:, None]
I0512 12:47:18.963203 140364252047168 robot_base.py:42] Loading robot model file: turtlebot/turtlebot.urdf
I0512 12:47:19.707535 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/kobuki_description/meshes/main_body.obj
I0512 12:47:19.878240 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/mjcf_primitives/cube.obj
I0512 12:47:19.880599 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/kobuki_description/meshes/wheel.obj
I0512 12:47:19.933987 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/mjcf_primitives/cube.obj
I0512 12:47:19.934559 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/mjcf_primitives/cube.obj
I0512 12:47:19.935096 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/pole_bottom.obj
I0512 12:47:19.948763 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/plate_bottom.obj
I0512 12:47:20.066872 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/pole_middle.obj
I0512 12:47:20.078709 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/plate_middle.obj
I0512 12:47:20.192009 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/pole_top.obj
I0512 12:47:20.204359 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/pole_kinect.obj
I0512 12:47:20.218851 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/stacks/hexagons/plate_top.obj
I0512 12:47:20.253885 140364252047168 mesh_renderer_cpu.py:335] Loading /home/guttikon/activate-localization/igibson/gibson2/data/assets/models/turtlebot/turtlebot_description/meshes/sensors/kinect.obj
2021-05-12 12:47:20.386416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 12:47:20.592792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
W0512 12:47:20.613843 140364252047168 ppo_agent.py:329] Only tf.keras.optimizers.Optimiers are well supported, got a non-TF2 optimizer: <tensorflow.python.training.adam.AdamOptimizer object at 0x7fa8b6e853c8>
I0512 12:47:20.635725 140364252047168 common.py:980] No checkpoint available at test_output/train
I0512 12:47:20.638987 140364252047168 common.py:980] No checkpoint available at test_output/train/policy
2021-05-12 12:47:20.721031: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2021-05-12 12:47:20.746584: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-12 12:47:20.767298: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3199980000 Hz
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
WARNING:tensorflow:From train_eval_clip_agent.py:278: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=True)` instead.
W0512 12:48:56.926242 140364252047168 deprecation.py:339] From train_eval_clip_agent.py:278: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=True)` instead.
I0512 12:49:15.155077 140364252047168 train_eval_clip_agent.py:318] step = 0, loss = -0.008234
I0512 12:49:15.155942 140364252047168 train_eval_clip_agent.py:321] 0.000 steps/sec
I0512 12:49:15.156042 140364252047168 train_eval_clip_agent.py:323] collect_time = 48.399, train_time = 18.135
I0512 12:49:15.378234 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-0
I0512 12:49:15.486352 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-0
W0512 12:49:16.027311 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 12:49:16.064944 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000000000/assets
I0512 12:49:16.303266 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000000000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 12:50:52.813348 140364252047168 train_eval_clip_agent.py:318] step = 50, loss = -0.014825
I0512 12:50:52.814084 140364252047168 train_eval_clip_agent.py:321] 0.518 steps/sec
I0512 12:50:52.814163 140364252047168 train_eval_clip_agent.py:323] collect_time = 94.833, train_time = 1.616
I0512 12:52:29.031132 140364252047168 train_eval_clip_agent.py:318] step = 100, loss = -0.024278
I0512 12:52:29.040479 140364252047168 train_eval_clip_agent.py:321] 0.520 steps/sec
I0512 12:52:29.040575 140364252047168 train_eval_clip_agent.py:323] collect_time = 94.600, train_time = 1.602
I0512 12:54:00.277561 140364252047168 train_eval_clip_agent.py:318] step = 150, loss = -0.013652
I0512 12:54:00.278280 140364252047168 train_eval_clip_agent.py:321] 0.548 steps/sec
I0512 12:54:00.278354 140364252047168 train_eval_clip_agent.py:323] collect_time = 89.658, train_time = 1.563
I0512 12:55:11.151947 140364252047168 train_eval_clip_agent.py:318] step = 200, loss = 0.097388
I0512 12:55:11.152568 140364252047168 train_eval_clip_agent.py:321] 0.706 steps/sec
I0512 12:55:11.152640 140364252047168 train_eval_clip_agent.py:323] collect_time = 69.595, train_time = 1.264
I0512 12:56:12.898364 140364252047168 train_eval_clip_agent.py:318] step = 250, loss = 1.302200
I0512 12:56:12.898916 140364252047168 train_eval_clip_agent.py:321] 0.810 steps/sec
I0512 12:56:12.898989 140364252047168 train_eval_clip_agent.py:323] collect_time = 60.646, train_time = 1.086
I0512 12:57:04.886205 140364252047168 train_eval_clip_agent.py:318] step = 300, loss = 2.447137
I0512 12:57:04.886947 140364252047168 train_eval_clip_agent.py:321] 0.962 steps/sec
I0512 12:57:04.887019 140364252047168 train_eval_clip_agent.py:323] collect_time = 51.105, train_time = 0.869
I0512 12:58:06.190180 140364252047168 train_eval_clip_agent.py:318] step = 350, loss = 3.336510
I0512 12:58:06.197757 140364252047168 train_eval_clip_agent.py:321] 0.816 steps/sec
I0512 12:58:06.198024 140364252047168 train_eval_clip_agent.py:323] collect_time = 60.228, train_time = 1.061
I0512 12:58:32.771008 140364252047168 train_eval_clip_agent.py:318] step = 400, loss = 0.748998
I0512 12:58:32.771811 140364252047168 train_eval_clip_agent.py:321] 1.883 steps/sec
I0512 12:58:32.771882 140364252047168 train_eval_clip_agent.py:323] collect_time = 26.067, train_time = 0.490
I0512 12:58:58.283235 140364252047168 train_eval_clip_agent.py:318] step = 450, loss = 0.796865
I0512 12:58:58.283963 140364252047168 train_eval_clip_agent.py:321] 1.961 steps/sec
I0512 12:58:58.284035 140364252047168 train_eval_clip_agent.py:323] collect_time = 25.024, train_time = 0.474
I0512 12:59:33.083458 140364252047168 train_eval_clip_agent.py:318] step = 500, loss = 1.528939
I0512 12:59:33.084320 140364252047168 train_eval_clip_agent.py:321] 1.766 steps/sec
I0512 12:59:33.084391 140364252047168 train_eval_clip_agent.py:323] collect_time = 27.800, train_time = 0.520
I0512 12:59:33.383109 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-500
I0512 12:59:33.490824 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-500
W0512 12:59:33.862145 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 12:59:33.899774 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000000500/assets
I0512 12:59:34.129519 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000000500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:00:03.136539 140364252047168 train_eval_clip_agent.py:318] step = 550, loss = 5.604647
I0512 13:00:03.137431 140364252047168 train_eval_clip_agent.py:321] 1.728 steps/sec
I0512 13:00:03.137502 140364252047168 train_eval_clip_agent.py:323] collect_time = 28.418, train_time = 0.525
I0512 13:00:41.679347 140364252047168 train_eval_clip_agent.py:318] step = 600, loss = 5.808877
I0512 13:00:41.680055 140364252047168 train_eval_clip_agent.py:321] 1.298 steps/sec
I0512 13:00:41.680137 140364252047168 train_eval_clip_agent.py:323] collect_time = 37.854, train_time = 0.674
I0512 13:01:20.558429 140364252047168 train_eval_clip_agent.py:318] step = 650, loss = 3.342657
I0512 13:01:20.559116 140364252047168 train_eval_clip_agent.py:321] 1.287 steps/sec
I0512 13:01:20.559187 140364252047168 train_eval_clip_agent.py:323] collect_time = 38.194, train_time = 0.670
I0512 13:01:40.413265 140364252047168 train_eval_clip_agent.py:318] step = 700, loss = 0.258659
I0512 13:01:40.414004 140364252047168 train_eval_clip_agent.py:321] 2.520 steps/sec
I0512 13:01:40.414085 140364252047168 train_eval_clip_agent.py:323] collect_time = 19.467, train_time = 0.373
I0512 13:01:51.453117 140364252047168 train_eval_clip_agent.py:318] step = 750, loss = 0.164996
I0512 13:01:51.453943 140364252047168 train_eval_clip_agent.py:321] 4.536 steps/sec
I0512 13:01:51.454010 140364252047168 train_eval_clip_agent.py:323] collect_time = 10.784, train_time = 0.240
I0512 13:02:02.575182 140364252047168 train_eval_clip_agent.py:318] step = 800, loss = 0.438738
I0512 13:02:02.576045 140364252047168 train_eval_clip_agent.py:321] 4.502 steps/sec
I0512 13:02:02.576112 140364252047168 train_eval_clip_agent.py:323] collect_time = 10.862, train_time = 0.243
I0512 13:02:18.475116 140364252047168 train_eval_clip_agent.py:318] step = 850, loss = 0.587634
I0512 13:02:18.476105 140364252047168 train_eval_clip_agent.py:321] 3.148 steps/sec
I0512 13:02:18.476170 140364252047168 train_eval_clip_agent.py:323] collect_time = 15.583, train_time = 0.301
I0512 13:02:27.213357 140364252047168 train_eval_clip_agent.py:318] step = 900, loss = -0.027387
I0512 13:02:27.214203 140364252047168 train_eval_clip_agent.py:321] 5.733 steps/sec
I0512 13:02:27.214268 140364252047168 train_eval_clip_agent.py:323] collect_time = 8.519, train_time = 0.203
I0512 13:02:40.826782 140364252047168 train_eval_clip_agent.py:318] step = 950, loss = 0.112077
I0512 13:02:40.827516 140364252047168 train_eval_clip_agent.py:321] 3.677 steps/sec
I0512 13:02:40.827584 140364252047168 train_eval_clip_agent.py:323] collect_time = 13.320, train_time = 0.277
I0512 13:02:57.015134 140364252047168 train_eval_clip_agent.py:318] step = 1000, loss = 2.216497
I0512 13:02:57.016027 140364252047168 train_eval_clip_agent.py:321] 4.338 steps/sec
I0512 13:02:57.016096 140364252047168 train_eval_clip_agent.py:323] collect_time = 11.272, train_time = 0.253
I0512 13:02:57.240054 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-1000
I0512 13:02:57.367439 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-1000
W0512 13:02:57.744608 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:02:57.782272 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000001000/assets
I0512 13:02:58.015538 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000001000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:03:26.501318 140364252047168 train_eval_clip_agent.py:318] step = 1050, loss = 3.857968
I0512 13:03:26.502085 140364252047168 train_eval_clip_agent.py:321] 1.761 steps/sec
I0512 13:03:26.502156 140364252047168 train_eval_clip_agent.py:323] collect_time = 27.877, train_time = 0.517
I0512 13:03:47.809519 140364252047168 train_eval_clip_agent.py:318] step = 1100, loss = 1.681191
I0512 13:03:47.818353 140364252047168 train_eval_clip_agent.py:321] 2.348 steps/sec
I0512 13:03:47.818423 140364252047168 train_eval_clip_agent.py:323] collect_time = 20.925, train_time = 0.370
I0512 13:04:01.968243 140364252047168 train_eval_clip_agent.py:318] step = 1150, loss = 0.108194
I0512 13:04:01.977783 140364252047168 train_eval_clip_agent.py:321] 3.537 steps/sec
I0512 13:04:01.977856 140364252047168 train_eval_clip_agent.py:323] collect_time = 13.850, train_time = 0.286
I0512 13:04:19.574981 140364252047168 train_eval_clip_agent.py:318] step = 1200, loss = -0.057191
I0512 13:04:19.575708 140364252047168 train_eval_clip_agent.py:321] 2.844 steps/sec
I0512 13:04:19.575784 140364252047168 train_eval_clip_agent.py:323] collect_time = 17.241, train_time = 0.342
I0512 13:04:27.822023 140364252047168 train_eval_clip_agent.py:318] step = 1250, loss = -0.114536
I0512 13:04:27.829956 140364252047168 train_eval_clip_agent.py:321] 6.075 steps/sec
I0512 13:04:27.830244 140364252047168 train_eval_clip_agent.py:323] collect_time = 8.039, train_time = 0.191
I0512 13:04:35.386713 140364252047168 train_eval_clip_agent.py:318] step = 1300, loss = -0.125079
I0512 13:04:35.386987 140364252047168 train_eval_clip_agent.py:321] 6.633 steps/sec
I0512 13:04:35.387052 140364252047168 train_eval_clip_agent.py:323] collect_time = 7.356, train_time = 0.182
I0512 13:04:43.029226 140364252047168 train_eval_clip_agent.py:318] step = 1350, loss = -0.122697
I0512 13:04:43.037572 140364252047168 train_eval_clip_agent.py:321] 6.556 steps/sec
I0512 13:04:43.037837 140364252047168 train_eval_clip_agent.py:323] collect_time = 7.443, train_time = 0.183
I0512 13:04:51.017209 140364252047168 train_eval_clip_agent.py:318] step = 1400, loss = 0.061538
I0512 13:04:51.027558 140364252047168 train_eval_clip_agent.py:321] 6.280 steps/sec
I0512 13:04:51.027837 140364252047168 train_eval_clip_agent.py:323] collect_time = 7.774, train_time = 0.188
I0512 13:04:57.758173 140364252047168 train_eval_clip_agent.py:318] step = 1450, loss = -0.085905
I0512 13:04:57.759083 140364252047168 train_eval_clip_agent.py:321] 7.449 steps/sec
I0512 13:04:57.759150 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.545, train_time = 0.167
I0512 13:05:07.838662 140364252047168 train_eval_clip_agent.py:318] step = 1500, loss = -0.147059
I0512 13:05:07.838870 140364252047168 train_eval_clip_agent.py:321] 7.370 steps/sec
I0512 13:05:07.838939 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.616, train_time = 0.168
I0512 13:05:08.700031 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-1500
I0512 13:05:09.100534 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-1500
W0512 13:05:09.577744 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:05:09.615422 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000001500/assets
I0512 13:05:10.271181 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000001500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:05:17.326917 140364252047168 train_eval_clip_agent.py:318] step = 1550, loss = -0.151192
I0512 13:05:17.327195 140364252047168 train_eval_clip_agent.py:321] 7.316 steps/sec
I0512 13:05:17.327259 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.664, train_time = 0.170
I0512 13:05:28.057242 140364252047168 train_eval_clip_agent.py:318] step = 1600, loss = -0.045668
I0512 13:05:28.065751 140364252047168 train_eval_clip_agent.py:321] 4.666 steps/sec
I0512 13:05:28.066052 140364252047168 train_eval_clip_agent.py:323] collect_time = 10.478, train_time = 0.237
I0512 13:05:35.119303 140364252047168 train_eval_clip_agent.py:318] step = 1650, loss = -0.055247
I0512 13:05:35.127962 140364252047168 train_eval_clip_agent.py:321] 7.108 steps/sec
I0512 13:05:35.128273 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.866, train_time = 0.169
I0512 13:05:41.782697 140364252047168 train_eval_clip_agent.py:318] step = 1700, loss = -0.150002
I0512 13:05:41.783581 140364252047168 train_eval_clip_agent.py:321] 7.535 steps/sec
I0512 13:05:41.783648 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.469, train_time = 0.167
I0512 13:05:48.967296 140364252047168 train_eval_clip_agent.py:318] step = 1750, loss = 0.178658
I0512 13:05:48.967534 140364252047168 train_eval_clip_agent.py:321] 6.976 steps/sec
I0512 13:05:48.967601 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.992, train_time = 0.176
I0512 13:05:55.555346 140364252047168 train_eval_clip_agent.py:318] step = 1800, loss = -0.147015
I0512 13:05:55.556226 140364252047168 train_eval_clip_agent.py:321] 7.609 steps/sec
I0512 13:05:55.556298 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.407, train_time = 0.164
I0512 13:06:02.145004 140364252047168 train_eval_clip_agent.py:318] step = 1850, loss = -0.159116
I0512 13:06:02.145833 140364252047168 train_eval_clip_agent.py:321] 7.607 steps/sec
I0512 13:06:02.145915 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.407, train_time = 0.166
I0512 13:06:08.612996 140364252047168 train_eval_clip_agent.py:318] step = 1900, loss = -0.156825
I0512 13:06:08.613289 140364252047168 train_eval_clip_agent.py:321] 7.751 steps/sec
I0512 13:06:08.613353 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.278, train_time = 0.173
I0512 13:06:15.028435 140364252047168 train_eval_clip_agent.py:318] step = 1950, loss = -0.156366
I0512 13:06:15.029274 140364252047168 train_eval_clip_agent.py:321] 7.814 steps/sec
I0512 13:06:15.029342 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.236, train_time = 0.162
I0512 13:06:24.416069 140364252047168 train_eval_clip_agent.py:318] step = 2000, loss = -0.164005
I0512 13:06:24.416816 140364252047168 train_eval_clip_agent.py:321] 7.874 steps/sec
I0512 13:06:24.416892 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.186, train_time = 0.165
I0512 13:06:24.663451 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-2000
I0512 13:06:24.780189 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-2000
W0512 13:06:25.180952 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:06:25.219333 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000002000/assets
I0512 13:06:25.450501 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000002000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:06:31.700343 140364252047168 train_eval_clip_agent.py:318] step = 2050, loss = -0.164321
I0512 13:06:31.701078 140364252047168 train_eval_clip_agent.py:321] 8.101 steps/sec
I0512 13:06:31.701146 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.012, train_time = 0.160
I0512 13:06:37.958956 140364252047168 train_eval_clip_agent.py:318] step = 2100, loss = -0.158010
I0512 13:06:37.959228 140364252047168 train_eval_clip_agent.py:321] 8.011 steps/sec
I0512 13:06:37.959298 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.081, train_time = 0.161
I0512 13:06:44.175425 140364252047168 train_eval_clip_agent.py:318] step = 2150, loss = -0.166644
I0512 13:06:44.176209 140364252047168 train_eval_clip_agent.py:321] 8.064 steps/sec
I0512 13:06:44.176286 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.041, train_time = 0.159
I0512 13:06:50.511321 140364252047168 train_eval_clip_agent.py:318] step = 2200, loss = -0.161654
I0512 13:06:50.511561 140364252047168 train_eval_clip_agent.py:321] 7.913 steps/sec
I0512 13:06:50.511625 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.156, train_time = 0.162
I0512 13:06:56.746571 140364252047168 train_eval_clip_agent.py:318] step = 2250, loss = -0.158435
I0512 13:06:56.746789 140364252047168 train_eval_clip_agent.py:321] 8.040 steps/sec
I0512 13:06:56.746854 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.060, train_time = 0.159
I0512 13:07:02.861015 140364252047168 train_eval_clip_agent.py:318] step = 2300, loss = -0.169727
I0512 13:07:02.861898 140364252047168 train_eval_clip_agent.py:321] 8.199 steps/sec
I0512 13:07:02.861968 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.942, train_time = 0.157
I0512 13:07:08.971657 140364252047168 train_eval_clip_agent.py:318] step = 2350, loss = -0.157761
I0512 13:07:08.972508 140364252047168 train_eval_clip_agent.py:321] 8.205 steps/sec
I0512 13:07:08.972574 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.935, train_time = 0.159
I0512 13:07:15.096293 140364252047168 train_eval_clip_agent.py:318] step = 2400, loss = -0.166536
I0512 13:07:15.096574 140364252047168 train_eval_clip_agent.py:321] 8.187 steps/sec
I0512 13:07:15.096638 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.951, train_time = 0.156
I0512 13:07:21.157300 140364252047168 train_eval_clip_agent.py:318] step = 2450, loss = -0.165313
I0512 13:07:21.158128 140364252047168 train_eval_clip_agent.py:321] 8.271 steps/sec
I0512 13:07:21.158203 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.888, train_time = 0.157
I0512 13:07:30.214214 140364252047168 train_eval_clip_agent.py:318] step = 2500, loss = -0.170723
I0512 13:07:30.214504 140364252047168 train_eval_clip_agent.py:321] 8.200 steps/sec
I0512 13:07:30.214569 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.941, train_time = 0.156
I0512 13:07:30.428297 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-2500
I0512 13:07:30.542616 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-2500
W0512 13:07:31.084430 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:07:31.121958 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000002500/assets
I0512 13:07:31.366763 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000002500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:07:37.724190 140364252047168 train_eval_clip_agent.py:318] step = 2550, loss = -0.164562
I0512 13:07:37.725076 140364252047168 train_eval_clip_agent.py:321] 7.976 steps/sec
I0512 13:07:37.725375 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.107, train_time = 0.162
I0512 13:07:43.841022 140364252047168 train_eval_clip_agent.py:318] step = 2600, loss = -0.165515
I0512 13:07:43.841647 140364252047168 train_eval_clip_agent.py:321] 8.200 steps/sec
I0512 13:07:43.841715 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.941, train_time = 0.156
I0512 13:07:49.800368 140364252047168 train_eval_clip_agent.py:318] step = 2650, loss = -0.170518
I0512 13:07:49.800593 140364252047168 train_eval_clip_agent.py:321] 8.413 steps/sec
I0512 13:07:49.800670 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.788, train_time = 0.155
I0512 13:07:55.946563 140364252047168 train_eval_clip_agent.py:318] step = 2700, loss = -0.168670
I0512 13:07:55.947377 140364252047168 train_eval_clip_agent.py:321] 8.157 steps/sec
I0512 13:07:55.947446 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.970, train_time = 0.159
I0512 13:08:02.042143 140364252047168 train_eval_clip_agent.py:318] step = 2750, loss = -0.162146
I0512 13:08:02.042425 140364252047168 train_eval_clip_agent.py:321] 8.226 steps/sec
I0512 13:08:02.042488 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.920, train_time = 0.158
I0512 13:08:07.991060 140364252047168 train_eval_clip_agent.py:318] step = 2800, loss = -0.172632
I0512 13:08:08.002929 140364252047168 train_eval_clip_agent.py:321] 8.427 steps/sec
I0512 13:08:08.003004 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.777, train_time = 0.156
I0512 13:08:13.958365 140364252047168 train_eval_clip_agent.py:318] step = 2850, loss = -0.170680
I0512 13:08:13.958624 140364252047168 train_eval_clip_agent.py:321] 8.418 steps/sec
I0512 13:08:13.958688 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.786, train_time = 0.154
I0512 13:08:19.937307 140364252047168 train_eval_clip_agent.py:318] step = 2900, loss = -0.166398
I0512 13:08:19.938122 140364252047168 train_eval_clip_agent.py:321] 8.385 steps/sec
I0512 13:08:19.938185 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.807, train_time = 0.155
I0512 13:08:25.922013 140364252047168 train_eval_clip_agent.py:318] step = 2950, loss = -0.168915
I0512 13:08:25.922289 140364252047168 train_eval_clip_agent.py:321] 8.380 steps/sec
I0512 13:08:25.922364 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.812, train_time = 0.155
I0512 13:08:34.969162 140364252047168 train_eval_clip_agent.py:318] step = 3000, loss = -0.165938
I0512 13:08:34.970043 140364252047168 train_eval_clip_agent.py:321] 8.280 steps/sec
I0512 13:08:34.970116 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.882, train_time = 0.156
I0512 13:08:35.222530 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-3000
I0512 13:08:35.348788 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-3000
W0512 13:08:35.753164 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:08:35.791206 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000003000/assets
I0512 13:08:36.024043 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000003000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:08:42.143741 140364252047168 train_eval_clip_agent.py:318] step = 3050, loss = -0.170731
I0512 13:08:42.144614 140364252047168 train_eval_clip_agent.py:321] 8.297 steps/sec
I0512 13:08:42.144679 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.871, train_time = 0.156
I0512 13:08:48.168651 140364252047168 train_eval_clip_agent.py:318] step = 3100, loss = -0.163117
I0512 13:08:48.168871 140364252047168 train_eval_clip_agent.py:321] 8.322 steps/sec
I0512 13:08:48.168937 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.851, train_time = 0.157
I0512 13:08:54.114907 140364252047168 train_eval_clip_agent.py:318] step = 3150, loss = -0.168923
I0512 13:08:54.115119 140364252047168 train_eval_clip_agent.py:321] 8.432 steps/sec
I0512 13:08:54.115183 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.775, train_time = 0.155
I0512 13:09:00.087635 140364252047168 train_eval_clip_agent.py:318] step = 3200, loss = -0.161207
I0512 13:09:00.088541 140364252047168 train_eval_clip_agent.py:321] 8.394 steps/sec
I0512 13:09:00.088616 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.803, train_time = 0.153
I0512 13:09:06.175929 140364252047168 train_eval_clip_agent.py:318] step = 3250, loss = -0.166319
I0512 13:09:06.176595 140364252047168 train_eval_clip_agent.py:321] 8.235 steps/sec
I0512 13:09:06.176667 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.914, train_time = 0.158
I0512 13:09:12.411191 140364252047168 train_eval_clip_agent.py:318] step = 3300, loss = -0.140159
I0512 13:09:12.411948 140364252047168 train_eval_clip_agent.py:321] 8.040 steps/sec
I0512 13:09:12.412013 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.058, train_time = 0.161
I0512 13:09:18.555716 140364252047168 train_eval_clip_agent.py:318] step = 3350, loss = -0.157225
I0512 13:09:18.555975 140364252047168 train_eval_clip_agent.py:321] 8.159 steps/sec
I0512 13:09:18.556046 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.971, train_time = 0.157
I0512 13:09:24.405098 140364252047168 train_eval_clip_agent.py:318] step = 3400, loss = -0.170052
I0512 13:09:24.405313 140364252047168 train_eval_clip_agent.py:321] 8.573 steps/sec
I0512 13:09:24.405377 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.678, train_time = 0.155
I0512 13:09:30.392336 140364252047168 train_eval_clip_agent.py:318] step = 3450, loss = -0.169171
I0512 13:09:30.392995 140364252047168 train_eval_clip_agent.py:321] 8.372 steps/sec
I0512 13:09:30.393059 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.816, train_time = 0.156
I0512 13:09:39.377147 140364252047168 train_eval_clip_agent.py:318] step = 3500, loss = -0.171116
I0512 13:09:39.377949 140364252047168 train_eval_clip_agent.py:321] 8.438 steps/sec
I0512 13:09:39.378024 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.772, train_time = 0.154
I0512 13:09:39.593146 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-3500
I0512 13:09:39.696028 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-3500
W0512 13:09:40.096247 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:09:40.133540 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000003500/assets
I0512 13:09:40.364302 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000003500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:09:46.289131 140364252047168 train_eval_clip_agent.py:318] step = 3550, loss = -0.176204
I0512 13:09:46.289931 140364252047168 train_eval_clip_agent.py:321] 8.533 steps/sec
I0512 13:09:46.290000 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.707, train_time = 0.153
I0512 13:09:52.194489 140364252047168 train_eval_clip_agent.py:318] step = 3600, loss = -0.176665
I0512 13:09:52.194752 140364252047168 train_eval_clip_agent.py:321] 8.491 steps/sec
I0512 13:09:52.194813 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.735, train_time = 0.154
I0512 13:09:58.069000 140364252047168 train_eval_clip_agent.py:318] step = 3650, loss = -0.172487
I0512 13:09:58.069294 140364252047168 train_eval_clip_agent.py:321] 8.535 steps/sec
I0512 13:09:58.069358 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.706, train_time = 0.153
I0512 13:10:04.132426 140364252047168 train_eval_clip_agent.py:318] step = 3700, loss = -0.168744
I0512 13:10:04.133334 140364252047168 train_eval_clip_agent.py:321] 8.268 steps/sec
I0512 13:10:04.133399 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.891, train_time = 0.156
I0512 13:10:10.082481 140364252047168 train_eval_clip_agent.py:318] step = 3750, loss = -0.170007
I0512 13:10:10.082692 140364252047168 train_eval_clip_agent.py:321] 8.426 steps/sec
I0512 13:10:10.082768 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.779, train_time = 0.154
I0512 13:10:16.138252 140364252047168 train_eval_clip_agent.py:318] step = 3800, loss = -0.167494
I0512 13:10:16.139085 140364252047168 train_eval_clip_agent.py:321] 8.278 steps/sec
I0512 13:10:16.139153 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.885, train_time = 0.156
I0512 13:10:22.080443 140364252047168 train_eval_clip_agent.py:318] step = 3850, loss = -0.169551
I0512 13:10:22.080617 140364252047168 train_eval_clip_agent.py:321] 8.436 steps/sec
I0512 13:10:22.080680 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.776, train_time = 0.151
I0512 13:10:27.967766 140364252047168 train_eval_clip_agent.py:318] step = 3900, loss = -0.171602
I0512 13:10:27.968523 140364252047168 train_eval_clip_agent.py:321] 8.515 steps/sec
I0512 13:10:27.968598 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.714, train_time = 0.158
I0512 13:10:33.922523 140364252047168 train_eval_clip_agent.py:318] step = 3950, loss = -0.172277
I0512 13:10:33.922749 140364252047168 train_eval_clip_agent.py:321] 8.421 steps/sec
I0512 13:10:33.922827 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.784, train_time = 0.154
I0512 13:10:42.930606 140364252047168 train_eval_clip_agent.py:318] step = 4000, loss = -0.173394
I0512 13:10:42.931544 140364252047168 train_eval_clip_agent.py:321] 8.288 steps/sec
I0512 13:10:42.931611 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.878, train_time = 0.155
I0512 13:10:43.164701 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-4000
I0512 13:10:43.275614 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-4000
W0512 13:10:43.677362 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:10:43.714762 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000004000/assets
I0512 13:10:43.941424 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000004000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:10:49.998836 140364252047168 train_eval_clip_agent.py:318] step = 4050, loss = -0.173317
I0512 13:10:49.999634 140364252047168 train_eval_clip_agent.py:321] 8.344 steps/sec
I0512 13:10:49.999698 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.838, train_time = 0.154
I0512 13:10:55.912446 140364252047168 train_eval_clip_agent.py:318] step = 4100, loss = -0.173389
I0512 13:10:55.912688 140364252047168 train_eval_clip_agent.py:321] 8.479 steps/sec
I0512 13:10:55.912762 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.734, train_time = 0.163
I0512 13:11:01.971311 140364252047168 train_eval_clip_agent.py:318] step = 4150, loss = -0.166662
I0512 13:11:01.972163 140364252047168 train_eval_clip_agent.py:321] 8.275 steps/sec
I0512 13:11:01.972228 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.887, train_time = 0.156
I0512 13:11:07.917793 140364252047168 train_eval_clip_agent.py:318] step = 4200, loss = -0.165291
I0512 13:11:07.918667 140364252047168 train_eval_clip_agent.py:321] 8.432 steps/sec
I0512 13:11:07.918745 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.776, train_time = 0.154
I0512 13:11:13.773874 140364252047168 train_eval_clip_agent.py:318] step = 4250, loss = -0.152088
I0512 13:11:13.774517 140364252047168 train_eval_clip_agent.py:321] 8.561 steps/sec
I0512 13:11:13.774591 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.687, train_time = 0.153
I0512 13:11:19.663756 140364252047168 train_eval_clip_agent.py:318] step = 4300, loss = -0.160027
I0512 13:11:19.664002 140364252047168 train_eval_clip_agent.py:321] 8.513 steps/sec
I0512 13:11:19.664067 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.720, train_time = 0.153
I0512 13:11:25.602154 140364252047168 train_eval_clip_agent.py:318] step = 4350, loss = -0.164461
I0512 13:11:25.602424 140364252047168 train_eval_clip_agent.py:321] 8.444 steps/sec
I0512 13:11:25.602486 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.767, train_time = 0.155
I0512 13:11:31.560904 140364252047168 train_eval_clip_agent.py:318] step = 4400, loss = -0.164977
I0512 13:11:31.561189 140364252047168 train_eval_clip_agent.py:321] 8.414 steps/sec
I0512 13:11:31.561253 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.790, train_time = 0.152
I0512 13:11:37.687767 140364252047168 train_eval_clip_agent.py:318] step = 4450, loss = -0.169117
I0512 13:11:37.688591 140364252047168 train_eval_clip_agent.py:321] 8.182 steps/sec
I0512 13:11:37.688668 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.956, train_time = 0.155
I0512 13:11:46.615239 140364252047168 train_eval_clip_agent.py:318] step = 4500, loss = -0.168849
I0512 13:11:46.615969 140364252047168 train_eval_clip_agent.py:321] 8.510 steps/sec
I0512 13:11:46.616040 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.720, train_time = 0.155
I0512 13:11:46.823790 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-4500
I0512 13:11:46.915532 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-4500
W0512 13:11:47.297655 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:11:47.335915 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000004500/assets
I0512 13:11:47.569595 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000004500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:11:53.557240 140364252047168 train_eval_clip_agent.py:318] step = 4550, loss = -0.165525
I0512 13:11:53.558022 140364252047168 train_eval_clip_agent.py:321] 8.451 steps/sec
I0512 13:11:53.558089 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.763, train_time = 0.154
I0512 13:11:59.456185 140364252047168 train_eval_clip_agent.py:318] step = 4600, loss = -0.160543
I0512 13:11:59.456429 140364252047168 train_eval_clip_agent.py:321] 8.500 steps/sec
I0512 13:11:59.456490 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.728, train_time = 0.154
I0512 13:12:05.452450 140364252047168 train_eval_clip_agent.py:318] step = 4650, loss = -0.165236
I0512 13:12:05.452694 140364252047168 train_eval_clip_agent.py:321] 8.360 steps/sec
I0512 13:12:05.452761 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.825, train_time = 0.155
I0512 13:12:11.626774 140364252047168 train_eval_clip_agent.py:318] step = 4700, loss = -0.125782
I0512 13:12:11.627061 140364252047168 train_eval_clip_agent.py:321] 8.119 steps/sec
I0512 13:12:11.627126 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.997, train_time = 0.161
I0512 13:12:17.906772 140364252047168 train_eval_clip_agent.py:318] step = 4750, loss = -0.158121
I0512 13:12:17.907041 140364252047168 train_eval_clip_agent.py:321] 7.983 steps/sec
I0512 13:12:17.907104 140364252047168 train_eval_clip_agent.py:323] collect_time = 6.101, train_time = 0.162
I0512 13:12:23.799009 140364252047168 train_eval_clip_agent.py:318] step = 4800, loss = -0.155077
I0512 13:12:23.799855 140364252047168 train_eval_clip_agent.py:321] 8.509 steps/sec
I0512 13:12:23.799923 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.723, train_time = 0.153
I0512 13:12:29.707962 140364252047168 train_eval_clip_agent.py:318] step = 4850, loss = -0.158508
I0512 13:12:29.708688 140364252047168 train_eval_clip_agent.py:321] 8.485 steps/sec
I0512 13:12:29.708753 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.736, train_time = 0.157
I0512 13:12:35.784828 140364252047168 train_eval_clip_agent.py:318] step = 4900, loss = -0.122537
I0512 13:12:35.785627 140364252047168 train_eval_clip_agent.py:321] 8.251 steps/sec
I0512 13:12:35.785693 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.904, train_time = 0.156
I0512 13:12:41.712782 140364252047168 train_eval_clip_agent.py:318] step = 4950, loss = -0.165494
I0512 13:12:41.713019 140364252047168 train_eval_clip_agent.py:321] 8.458 steps/sec
I0512 13:12:41.713086 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.758, train_time = 0.154
I0512 13:12:50.778565 140364252047168 train_eval_clip_agent.py:318] step = 5000, loss = -0.159914
I0512 13:12:50.779424 140364252047168 train_eval_clip_agent.py:321] 8.163 steps/sec
I0512 13:12:50.779493 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.968, train_time = 0.157
I0512 13:12:51.018321 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-5000
I0512 13:12:51.135780 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-5000
W0512 13:12:51.537739 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:12:51.575286 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000005000/assets
I0512 13:12:51.807520 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000005000/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:12:57.841038 140364252047168 train_eval_clip_agent.py:318] step = 5050, loss = -0.168715
I0512 13:12:57.841801 140364252047168 train_eval_clip_agent.py:321] 8.411 steps/sec
I0512 13:12:57.841867 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.791, train_time = 0.154
I0512 13:13:03.820393 140364252047168 train_eval_clip_agent.py:318] step = 5100, loss = -0.165103
I0512 13:13:03.820665 140364252047168 train_eval_clip_agent.py:321] 8.386 steps/sec
I0512 13:13:03.820726 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.809, train_time = 0.153
I0512 13:13:09.662736 140364252047168 train_eval_clip_agent.py:318] step = 5150, loss = -0.146749
I0512 13:13:09.662975 140364252047168 train_eval_clip_agent.py:321] 8.582 steps/sec
I0512 13:13:09.663037 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.675, train_time = 0.151
I0512 13:13:15.687299 140364252047168 train_eval_clip_agent.py:318] step = 5200, loss = -0.160642
I0512 13:13:15.688058 140364252047168 train_eval_clip_agent.py:321] 8.320 steps/sec
I0512 13:13:15.688133 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.852, train_time = 0.157
I0512 13:13:21.750896 140364252047168 train_eval_clip_agent.py:318] step = 5250, loss = -0.157831
I0512 13:13:21.751860 140364252047168 train_eval_clip_agent.py:321] 8.270 steps/sec
I0512 13:13:21.752121 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.889, train_time = 0.157
I0512 13:13:27.656259 140364252047168 train_eval_clip_agent.py:318] step = 5300, loss = -0.159367
I0512 13:13:27.656483 140364252047168 train_eval_clip_agent.py:321] 8.495 steps/sec
I0512 13:13:27.656559 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.733, train_time = 0.153
I0512 13:13:33.386659 140364252047168 train_eval_clip_agent.py:318] step = 5350, loss = -0.162016
I0512 13:13:33.387536 140364252047168 train_eval_clip_agent.py:321] 8.749 steps/sec
I0512 13:13:33.387602 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.564, train_time = 0.150
I0512 13:13:39.228771 140364252047168 train_eval_clip_agent.py:318] step = 5400, loss = -0.109505
I0512 13:13:39.229039 140364252047168 train_eval_clip_agent.py:321] 8.584 steps/sec
I0512 13:13:39.229112 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.671, train_time = 0.153
I0512 13:13:45.041870 140364252047168 train_eval_clip_agent.py:318] step = 5450, loss = -0.162753
I0512 13:13:45.042094 140364252047168 train_eval_clip_agent.py:321] 8.626 steps/sec
I0512 13:13:45.042155 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.645, train_time = 0.152
I0512 13:13:53.928040 140364252047168 train_eval_clip_agent.py:318] step = 5500, loss = -0.161286
I0512 13:13:53.928940 140364252047168 train_eval_clip_agent.py:321] 8.557 steps/sec
I0512 13:13:53.929005 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.692, train_time = 0.151
I0512 13:13:54.172917 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-5500
I0512 13:13:54.284198 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-5500
W0512 13:13:54.669381 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:13:54.706767 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000005500/assets
I0512 13:13:54.937393 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000005500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:14:00.882476 140364252047168 train_eval_clip_agent.py:318] step = 5550, loss = -0.153018
I0512 13:14:00.883297 140364252047168 train_eval_clip_agent.py:321] 8.525 steps/sec
I0512 13:14:00.883365 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.712, train_time = 0.153
I0512 13:14:06.651332 140364252047168 train_eval_clip_agent.py:318] step = 5600, loss = -0.149778
I0512 13:14:06.651573 140364252047168 train_eval_clip_agent.py:321] 8.693 steps/sec
I0512 13:14:06.651637 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.602, train_time = 0.150
I0512 13:14:12.626348 140364252047168 train_eval_clip_agent.py:318] step = 5650, loss = -0.166560
I0512 13:14:12.626574 140364252047168 train_eval_clip_agent.py:321] 8.390 steps/sec
I0512 13:14:12.626639 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.806, train_time = 0.154
I0512 13:14:18.704198 140364252047168 train_eval_clip_agent.py:318] step = 5700, loss = -0.130734
I0512 13:14:18.704991 140364252047168 train_eval_clip_agent.py:321] 8.247 steps/sec
I0512 13:14:18.705066 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.907, train_time = 0.155
I0512 13:14:24.662225 140364252047168 train_eval_clip_agent.py:318] step = 5750, loss = -0.132214
I0512 13:14:24.662513 140364252047168 train_eval_clip_agent.py:321] 8.416 steps/sec
I0512 13:14:24.662575 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.787, train_time = 0.154
I0512 13:14:30.495014 140364252047168 train_eval_clip_agent.py:318] step = 5800, loss = -0.113371
I0512 13:14:30.495276 140364252047168 train_eval_clip_agent.py:321] 8.597 steps/sec
I0512 13:14:30.495347 140364252047168 train_eval_clip_agent.py:323] collect_time = 5.664, train_time = 0.152
I0512 13:14:56.996065 140364252047168 train_eval_clip_agent.py:318] step = 5850, loss = 2.092039
I0512 13:14:56.996659 140364252047168 train_eval_clip_agent.py:321] 1.888 steps/sec
I0512 13:14:56.996730 140364252047168 train_eval_clip_agent.py:323] collect_time = 26.039, train_time = 0.448
I0512 13:15:33.609255 140364252047168 train_eval_clip_agent.py:318] step = 5900, loss = 0.363325
I0512 13:15:33.610038 140364252047168 train_eval_clip_agent.py:321] 1.366 steps/sec
I0512 13:15:33.610118 140364252047168 train_eval_clip_agent.py:323] collect_time = 35.922, train_time = 0.677
I0512 13:15:49.958830 140364252047168 train_eval_clip_agent.py:318] step = 5950, loss = 0.295790
I0512 13:15:49.959611 140364252047168 train_eval_clip_agent.py:321] 3.061 steps/sec
I0512 13:15:49.959688 140364252047168 train_eval_clip_agent.py:323] collect_time = 16.038, train_time = 0.297
I0512 13:18:10.155384 140364252047168 train_eval_clip_agent.py:318] step = 6000, loss = 0.632297
I0512 13:18:10.167698 140364252047168 train_eval_clip_agent.py:321] 0.555 steps/sec
I0512 13:18:10.167789 140364252047168 train_eval_clip_agent.py:323] collect_time = 88.747, train_time = 1.400
I0512 13:18:10.892822 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-6000
I0512 13:18:11.327754 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-6000
W0512 13:18:11.820186 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:18:11.857519 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000006000/assets
I0512 13:18:12.435963 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000006000/assets
I0512 13:20:16.460380 140364252047168 train_eval_clip_agent.py:318] step = 6050, loss = 0.594444
I0512 13:20:16.461153 140364252047168 train_eval_clip_agent.py:321] 0.404 steps/sec
I0512 13:20:16.461249 140364252047168 train_eval_clip_agent.py:323] collect_time = 122.193, train_time = 1.645
I0512 13:21:56.848367 140364252047168 train_eval_clip_agent.py:318] step = 6100, loss = 2.462168
I0512 13:21:56.849132 140364252047168 train_eval_clip_agent.py:321] 0.498 steps/sec
I0512 13:21:56.849204 140364252047168 train_eval_clip_agent.py:323] collect_time = 98.773, train_time = 1.599
I0512 13:23:43.979056 140364252047168 train_eval_clip_agent.py:318] step = 6150, loss = 0.326357
I0512 13:23:43.979886 140364252047168 train_eval_clip_agent.py:321] 0.467 steps/sec
I0512 13:23:43.979970 140364252047168 train_eval_clip_agent.py:323] collect_time = 105.461, train_time = 1.653
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:25:20.108157 140364252047168 train_eval_clip_agent.py:318] step = 6200, loss = 1.360214
I0512 13:25:20.108906 140364252047168 train_eval_clip_agent.py:321] 0.520 steps/sec
I0512 13:25:20.108983 140364252047168 train_eval_clip_agent.py:323] collect_time = 94.460, train_time = 1.652
I0512 13:26:55.815536 140364252047168 train_eval_clip_agent.py:318] step = 6250, loss = 1.301063
I0512 13:26:55.816225 140364252047168 train_eval_clip_agent.py:321] 0.523 steps/sec
I0512 13:26:55.816321 140364252047168 train_eval_clip_agent.py:323] collect_time = 94.064, train_time = 1.627
I0512 13:28:41.170044 140364252047168 train_eval_clip_agent.py:318] step = 6300, loss = 0.737811
I0512 13:28:41.177993 140364252047168 train_eval_clip_agent.py:321] 0.475 steps/sec
I0512 13:28:41.178256 140364252047168 train_eval_clip_agent.py:323] collect_time = 103.699, train_time = 1.639
I0512 13:30:36.482617 140364252047168 train_eval_clip_agent.py:318] step = 6350, loss = 0.700999
I0512 13:30:36.483410 140364252047168 train_eval_clip_agent.py:321] 0.434 steps/sec
I0512 13:30:36.483487 140364252047168 train_eval_clip_agent.py:323] collect_time = 113.638, train_time = 1.649
I0512 13:32:21.479502 140364252047168 train_eval_clip_agent.py:318] step = 6400, loss = 1.604465
I0512 13:32:21.480246 140364252047168 train_eval_clip_agent.py:321] 0.476 steps/sec
I0512 13:32:21.480320 140364252047168 train_eval_clip_agent.py:323] collect_time = 103.338, train_time = 1.642
I0512 13:33:57.021256 140364252047168 train_eval_clip_agent.py:318] step = 6450, loss = 0.359125
I0512 13:33:57.022029 140364252047168 train_eval_clip_agent.py:321] 0.523 steps/sec
I0512 13:33:57.022114 140364252047168 train_eval_clip_agent.py:323] collect_time = 93.906, train_time = 1.621
I0512 13:36:22.695820 140364252047168 train_eval_clip_agent.py:318] step = 6500, loss = 0.079967
I0512 13:36:22.696640 140364252047168 train_eval_clip_agent.py:321] 0.508 steps/sec
I0512 13:36:22.696736 140364252047168 train_eval_clip_agent.py:323] collect_time = 96.825, train_time = 1.637
I0512 13:36:22.954586 140364252047168 common.py:1003] Saved checkpoint: test_output/train/ckpt-6500
I0512 13:36:23.090117 140364252047168 common.py:1003] Saved checkpoint: test_output/train/policy/ckpt-6500
W0512 13:36:23.501308 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
W0512 13:36:23.539439 140364252047168 save.py:241] Found untraced functions such as ActorDistributionNetwork_layer_call_and_return_conditional_losses, ActorDistributionNetwork_layer_call_fn, ValueNetwork_layer_call_and_return_conditional_losses, ValueNetwork_layer_call_fn, EncodingNetwork_layer_call_and_return_conditional_losses while saving (showing 5 of 60). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: test_output/policy_saved_model/policy_000006500/assets
I0512 13:36:23.771699 140364252047168 builder_impl.py:775] Assets written to: test_output/policy_saved_model/policy_000006500/assets
/home/guttikon/activate-localization/igibson/gibson2/sensors/vision_sensor.py:93: RuntimeWarning: invalid value encountered in true_divide
  depth /= self.depth_high
I0512 13:38:00.737924 140364252047168 train_eval_clip_agent.py:318] step = 6550, loss = 0.254667
I0512 13:38:00.738838 140364252047168 train_eval_clip_agent.py:321] 0.516 steps/sec
I0512 13:38:00.738930 140364252047168 train_eval_clip_agent.py:323] collect_time = 95.230, train_time = 1.647
I0512 13:39:35.196637 140364252047168 train_eval_clip_agent.py:318] step = 6600, loss = -0.009916
I0512 13:39:35.197382 140364252047168 train_eval_clip_agent.py:321] 0.529 steps/sec
I0512 13:39:35.197470 140364252047168 train_eval_clip_agent.py:323] collect_time = 92.782, train_time = 1.660
I0512 13:41:13.808694 140364252047168 train_eval_clip_agent.py:318] step = 6650, loss = 0.013153
I0512 13:41:13.815891 140364252047168 train_eval_clip_agent.py:321] 0.507 steps/sec
I0512 13:41:13.816157 140364252047168 train_eval_clip_agent.py:323] collect_time = 96.949, train_time = 1.646
I0512 13:42:51.841715 140364252047168 train_eval_clip_agent.py:318] step = 6700, loss = 0.164746
I0512 13:42:51.842546 140364252047168 train_eval_clip_agent.py:321] 0.510 steps/sec
I0512 13:42:51.842640 140364252047168 train_eval_clip_agent.py:323] collect_time = 96.379, train_time = 1.630
I0512 13:44:31.148753 140364252047168 train_eval_clip_agent.py:318] step = 6750, loss = -0.020767
I0512 13:44:31.149499 140364252047168 train_eval_clip_agent.py:321] 0.504 steps/sec
I0512 13:44:31.149584 140364252047168 train_eval_clip_agent.py:323] collect_time = 97.452, train_time = 1.838
I0512 13:46:09.637873 140364252047168 train_eval_clip_agent.py:318] step = 6800, loss = -0.024455
I0512 13:46:09.638682 140364252047168 train_eval_clip_agent.py:321] 0.508 steps/sec
I0512 13:46:09.638778 140364252047168 train_eval_clip_agent.py:323] collect_time = 96.862, train_time = 1.611
I0512 13:47:47.987486 140364252047168 train_eval_clip_agent.py:318] step = 6850, loss = -0.027504
I0512 13:47:47.988304 140364252047168 train_eval_clip_agent.py:321] 0.508 steps/sec
I0512 13:47:47.988389 140364252047168 train_eval_clip_agent.py:323] collect_time = 96.676, train_time = 1.656
I0512 13:49:27.032232 140364252047168 train_eval_clip_agent.py:318] step = 6900, loss = -0.028151
I0512 13:49:27.033071 140364252047168 train_eval_clip_agent.py:321] 0.505 steps/sec
I0512 13:49:27.033156 140364252047168 train_eval_clip_agent.py:323] collect_time = 97.367, train_time = 1.662
torch is not available, falling back to rendering to memory(instead of tensor)
******************PyBullet Logging Information:
PyBullet Logging Information******************
=====> NavigateGibsonEnv initialized
observation_spec OrderedDict([('task_obs', BoundedTensorSpec(shape=(20,), dtype=tf.float32, name='observation/task_obs', minimum=array(-1000., dtype=float32), maximum=array(1000., dtype=float32)))])
action_spec BoundedTensorSpec(shape=(2,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))
