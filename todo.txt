May 5th 2021
------------
1. fix the rgb - nan/inf issue for non-parallel env
2. then try on-policy algorithm say PPO for navigation task (task_obs and rgb_obs)
3. then try to incorporate pfnet into rl agent

May 12th 2021
-------------
1. fix ppo with rgb_obs
2. test pretrained pfnet
3. check if end to end works or need any changes


end project goals:
1. reproduce pfnet on housing dataset
2. fine tuned it to igibson
3. use pretrained pfnet with rl agent ppo -> with better representation of particles
4. end-to-end pfnet + rl agent
5. baseline comparision

May 19th 2021
-------------
1. collect stats for random start position with random policy gaussian and uniform init distribution with/without transition noise
2. use tf profiling or some tool to narrow where the code is taking time
3. change local map for loop into batches
4. decrease batch size and number of steps

May 26th 2021
-------------
goal: better gaussian with noise
1. normalize reward in range [-10, 0]
2. provide est_pose to gt_pose to train rl_agent
3. plot mse per step metric for random and rl agent -
  a) different timesteps
  b) different number particles
  c) with and without transition noise
  d) different init covariance
4. try with large and smaller  [e-3, e-5] learning rates for sac
