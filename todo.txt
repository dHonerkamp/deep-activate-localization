May 5th 2021
------------
1. fix the rgb - nan/inf issue for non-parallel env
2. then try on-policy algorithm say PPO for navigation task (task_obs and rgb_obs)
3. then try to incorporate pfnet into rl agent

May 12th 2021
-------------
1. fix ppo with rgb_obs
2. test pretrained pfnet
3. check if end to end works or need any changes


end project goals:
1. reproduce pfnet on housing dataset
2. fine tuned it to igibson
3. use pretrained pfnet with rl agent ppo -> with better representation of particles
4. end-to-end pfnet + rl agent
5. baseline comparision

May 19th 2021
-------------
1. collect stats for random start position with random policy gaussian and uniform init distribution with/without transition noise
2. use tf profiling or some tool to narrow where the code is taking time
3. change local map for loop into batches
4. decrease batch size and number of steps

May 26th 2021
-------------
goal: better gaussian with noise
1. normalize reward in range [-10, 0]
2. provide est_pose to gt_pose to train rl_agent
3. plot mse per step metric for random and rl agent -
  a) different timesteps
  b) different number particles
  c) with and without transition noise
  d) different init covariance
4. try with large and smaller  [e-3, e-5] learning rates for sac

June 2nd 2021
-------------
0. plot avg mse per episode and end mse (> 50 eval eps, 150 eps steps plot unnormalized mse)
1. collect manual trajectory to cross check pfnet (discrete/continuous)
	- fine tuned vs non-finetuned
2. for rnd_agent
   a) fine tuned vs non-finetuned pfnet
   b) random starting position (say >100) with random maps/rooms
   c) different num_particles (500, 1000, 2000)
   d) different init distribution (gaussian, uniform)

python supervised_data.py \
--filename=./data/random/test0.tfrecord \
--agent='random' \
--num_records=25 \
--config_file=./configs/turtlebot_random_nav.yaml \
--env_mode='headless' \
--gpu_num=0 \
--init_env_pfnet=False \
--seed=90

$ nohup python -u test_pfnet.py \
--root_dir=./random/igibson_pfnet/run1 \
--pfnet_loadpath=./pfnetwork/checkpoints/pfnet_igibson_data/checkpoint_87_5.830/pfnet_checkpoint \
--num_eval_batches=50 \
--testfiles=./plots_data/random/*.tfrecord \
--batch_size=4 \
--init_particles_distr='gaussian' \
--init_particles_std '0.3' '0.523599' \
--num_particles=500 \
--transition_std '0.04' '0.0872665' \
--resample=true \
--alpha_resample_ratio=0.8 \
--global_map_size '4000' '4000' '1' \
--window_scaler=8.0 \
--config_file=./configs/turtlebot_random_nav.yaml \
--device_idx=0 \
--seed=15 > nohup1.out &

June 9th 2021
-------------
1. collect random trajectories w.r.t discrete actions and train PFNet
2. collect train/test for 200 houses with trajectory length 100, for 10,000 trajectories
3. then re-eval after training PFNet
4. K-mean representation of particles

$ nohup python -u supervised_data.py \
--filename=./pfnet_data/train/Rs0_floor0.tfrecord \
--scene_id='Rs' \
--agent='random' \
--num_records=500 \
--config_file=./configs/turtlebot_pfnet_nav.yaml \
--env_mode='headless' \
--gpu_num=0 \
--init_env_pfnet=False \
--seed=90 > nohup.out &


$ nohup python -u train_pfnet.py \
--root_dir=./run1 \
--tfrecordpath=./pfnet_data \
--epochs=20 \
--num_train_samples=37500 \
--num_eval_samples=2500 \
--batch_size=6 \
--s_buffer_size=500 \
--pfnet_loadpath=./pfnetwork/checkpoints/pfnet_igibson_data/checkpoint_87_5.830/pfnet_checkpoint \
--learning_rate=2.5e-3 \
--init_particles_distr='gaussian' \
--init_particles_std '0.3' '0.523599' \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--alpha_resample_ratio=0.5 \
--global_map_size '4000' '4000' '1' \
--window_scaler=8.0 \
--config_file=./configs/turtlebot_pfnet_nav.yaml \
--device_idx=1 \
--multiple_gpus=false \
--seed=42 > nohup.out &

max_step: 100
task_obs_dim: 18 # proprio + 3 (est_pose)

$ nohup python -u train_eval.py \
--root_dir=train_eval_output \
--num_iterations=250000 \
--initial_collect_steps=500 \
--collect_steps_per_iteration=1 \
--num_parallel_environments=1 \
--num_parallel_environments_eval=1 \
--replay_buffer_capacity=250000 \
--train_steps_per_iteration=1 \
--batch_size=1 \
--use_tf_functions=False \
--use_parallel_envs=False \
--num_eval_episodes=5 \
--eval_interval=1000 \
--eval_only=False \
--eval_deterministic=False \
--gpu_c=0 \
--is_localize_env=True \
--config_file=./configs/turtlebot_point_nav.yaml \
--env_mode=headless \
--gpu_g=0 \
--init_env_pfnet=True \
--init_particles_distr='gaussian' \
--init_particles_std=0.15,0.523599 \
--num_particles=1000 \
--resample=True \
--alpha_resample_ratio=1.0 \
--transition_std=0.02,0.0872665 \
--pfnet_load=./pfnetwork/checkpoints/pfnet_igibson_data/checkpoint_87_5.830/pfnet_checkpoint \
--use_plot=False \
--store_plot=False \
--seed=100 > nohup.out &

June 23rd 2021
--------------
1. train from scratch for single sequence - to check anything works
2. plot the trajectories on obstacle map to verify how diverse trajectories are
3. cross check for original dataset
4. different learning rate

$ nohup python -u display_pfnet_data.py \
--root_dir=./run1 \
--tfrecordpath=./pfnet_data \
--num_train_samples=500 \
--batch_size=1 \
--s_buffer_size=50 \
--init_particles_distr='gaussian' \
--init_particles_std '0.3' '0.523599' \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--alpha_resample_ratio=0.5 \
--global_map_size '2600' '2600' '1' \
--window_scaler=8.0 \
--config_file=./configs/turtlebot_pfnet_nav.yaml \
--device_idx=0 \
--seed=42 > nohup.out &

June 30th 2021
--------------
1. interactively check trained pfnet performance in real-time
2. check for over-fitting for train data
3. k-means representation of particles for rl agent training
4. reproduce pfnet paper results for RGB-D then proceed to igibson


valid.tfrecords: 830 records
test.tfrecords: 820 records
train.tfrecords: 74800 records

$ nohup python -u train.py \
--trainfiles './house3d_data/eval/valid.tfrecords' \
--evalfiles './house3d_data/eval/valid.tfrecords' \
--num_train_samples=816 \
--num_eval_samples=816 \
--obsmode='rgb-depth' \
--init_particles_distr='tracking' \
--init_particles_std '0.3' '0.523599' \
--trajlen=24 \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--batch_size=6 \
--learningrate=1e-4 \
--epochs=20 \
--gpu_num=0 \
--seed=42 > nohup2.out &
