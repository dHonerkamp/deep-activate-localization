May 5th 2021
------------
1. fix the rgb - nan/inf issue for non-parallel env
2. then try on-policy algorithm say PPO for navigation task (task_obs and rgb_obs)
3. then try to incorporate pfnet into rl agent

May 12th 2021
-------------
1. fix ppo with rgb_obs
2. test pretrained pfnet
3. check if end to end works or need any changes


end project goals:
1. reproduce pfnet on housing dataset
2. fine tuned it to igibson
3. use pretrained pfnet with rl agent ppo -> with better representation of particles
4. end-to-end pfnet + rl agent
5. baseline comparision

May 19th 2021
-------------
1. collect stats for random start position with random policy gaussian and uniform init distribution with/without transition noise
2. use tf profiling or some tool to narrow where the code is taking time
3. change local map for loop into batches
4. decrease batch size and number of steps

May 26th 2021
-------------
goal: better gaussian with noise
1. normalize reward in range [-10, 0]
2. provide est_pose to gt_pose to train rl_agent
3. plot mse per step metric for random and rl agent -
  a) different timesteps
  b) different number particles
  c) with and without transition noise
  d) different init covariance
4. try with large and smaller  [e-3, e-5] learning rates for sac

June 2nd 2021
-------------
0. plot avg mse per episode and end mse (> 50 eval eps, 150 eps steps plot unnormalized mse)
1. collect manual trajectory to cross check pfnet (discrete/continuous)
	- fine tuned vs non-finetuned
2. for rnd_agent
   a) fine tuned vs non-finetuned pfnet
   b) random starting position (say >100) with random maps/rooms
   c) different num_particles (500, 1000, 2000)
   d) different init distribution (gaussian, uniform)

$ nohup python -u test_pfnet.py \
--root_dir=./random/igibson_pfnet/run1 \
--pfnet_loadpath=./pfnetwork/checkpoints/pfnet_igibson_data/checkpoint_87_5.830/pfnet_checkpoint \
--obs_mode='rgb-depth' \
--num_eval_samples=50 \
--testfiles=./plots_data/random/*.tfrecord \
--batch_size=4 \
--custom_output 'rgb_obs' 'depth_obs' 'likelihood_map' \
--init_particles_distr='gaussian' \
--init_particles_std '0.15' '0.523599' \
--particles_range=100 \
--num_particles=500 \
--transition_std '0.02' '0.0872665' \
--resample=true \
--alpha_resample_ratio=0.8 \
--global_map_size '100' '100' '1' \
--window_scaler=1.0 \
--config_file=./configs/locobot_pfnet_nav.yaml \
--device_idx=0 \
--seed=15 > nohup1.out &

# real-time
$ nohup python -u test_pfnet.py \
--pfnet_loadpath=./pfnetwork/checkpoints/pfnet_igibson_data/checkpoint_63_0.136/pfnet_checkpoint \
--obs_mode='rgb-depth' \
--custom_output 'rgb_obs' 'depth_obs' 'likelihood_map' \
--scene_id='Rs' \
--init_particles_distr='gaussian' \
--init_particles_std '0.2' '0.523599' \
--particles_range=100 \
--num_particles=500 \
--transition_std '0.04' '0.0872665' \
--resample=true \
--alpha_resample_ratio=0.95 \
--global_map_size '100' '100' '1' \
--window_scaler=1.0 \
--config_file=./configs/locobot_pfnet_nav.yaml \
--device_idx=0 \
--seed=15 > nohup1.out &

# init fixed pose1
initial_pos: [-1.0, 0.35, 0.0] # as [x, y, z]
initial_orn: [0.0, 0.0, 0.0]
pose2
initial_pos: [0.0, 0.0, 0.0] # as [x, y, z]
initial_orn: [0.0, 0.0, 0.7]
pose3
initial_pos: [0.5, -2.0, 0.0] # as [x, y, z]
initial_orn: [0.0, 0.0, 1.7]
pose4
initial_pos: [-3.0, 0.8, 0.0] # as [x, y, z]
initial_orn: [0.0, 0.0, 1.2]
pose5
initial_pos: [0.5, 2.2, 0.0] # as [x, y, z]
initial_orn: [0.0, 0.0, 2.2]

June 9th 2021
-------------
1. collect random trajectories w.r.t discrete actions and train PFNet
2. collect train/test for 200 houses with trajectory length 100, for 10,000 trajectories
3. then re-eval after training PFNet
4. K-mean representation of particles

$ nohup python -u supervised_data.py \
--filename=./pfnet_data/train/Rs0_floor0.tfrecord \
--scene_id='Rs' \
--agent='avoid_agent' \
--num_records=5 \
--custom_output='rgb_obs','depth_obs','occupancy_grid','obstacle_obs' \
--config_file=./configs/locobot_pfnet_nav.yaml \
--env_mode='headless' \
--gpu_num=0 \
--init_env_pfnet=False \
--seed=90 > nohup.out &

0: --seed=136
1: --seed=489
2: --seed=1728
3: --seed=910
$ nohup python -u train_pfnet.py \
--root_dir=./run1 \
--tfrecordpath=./pfnet_data \
--epochs=100 \
--obs_mode='rgb-depth' \
--num_train_samples=4000 \
--num_eval_samples=500 \
--batch_size=12 \
--s_buffer_size=500 \
--pfnet_loadpath='' \
--learning_rate=5e-5 \
--init_particles_distr='gaussian' \
--init_particles_std '0.15' '0.523599' \
--particles_range=100 \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--alpha_resample_ratio=0.5 \
--global_map_size '100' '100' '1' \
--window_scaler=1.0 \
--config_file=./configs/locobot_pfnet_nav.yaml \
--device_idx=1 \
--multiple_gpus=false \
--seed=42 > nohup.out &

max_step: 100
task_obs_dim: 18 # proprio + 3 (est_pose)

$ nohup python -u train_eval.py \
--root_dir=train_rl_uniform \
--num_iterations=250000 \
--initial_collect_steps=500 \
--collect_steps_per_iteration=1 \
--num_parallel_environments=1 \
--num_parallel_environments_eval=1 \
--replay_buffer_capacity=2500 \
--train_steps_per_iteration=1 \
--batch_size=128 \
--actor_learning_rate=5e-05 \
--critic_learning_rate=5e-05 \
--alpha_learning_rate=5e-05 \
--use_tf_functions=False \
--use_parallel_envs=False \
--num_eval_episodes=10 \
--eval_interval=5000 \
--eval_only=False \
--eval_deterministic=False \
--gpu_c=0 \
--is_localize_env=True \
--config_file=./configs/locobot_pfnet_nav.yaml \
--env_mode=headless \
--gpu_g=0 \
--init_env_pfnet=True \
--init_particles_distr='uniform' \
--init_particles_std=0.2,0.523599 \
--particles_range=200 \
--num_particles=500 \
--resample=True \
--alpha_resample_ratio=0.99 \
--transition_std=0.04,0.0872665 \
--obs_mode='rgb-depth' \
--custom_output='rgb_obs','depth_obs','likelihood_map' \
--num_clusters=10 \
--global_map_size=100,100,1 \
--window_scaler=1.0 \
--pfnet_load=./pfnetwork/checkpoints/pfnet_igibson_data/report/rs_rgbd/checkpoint_28_0.065/pfnet_checkpoint \
--use_plot=False \
--store_plot=False \
--seed=100 > nohup_train_rl_uniform.out &

$ nohup python -u test_rl_agent.py \
--root_dir=train_rl_uniform \
--num_eval_episodes=10 \
--use_tf_functions=False \
--agent='sac_agent' \
--eval_deterministic=True \
--is_localize_env=True \
--config_file=./configs/locobot_pfnet_nav.yaml \
--gpu_num=0 \
--init_env_pfnet=True \
--init_particles_distr='uniform' \
--init_particles_std=0.2,0.523599 \
--particles_range=200 \
--num_particles=500 \
--resample=True \
--alpha_resample_ratio=0.99 \
--transition_std=0.04,0.0872665 \
--obs_mode='rgb-depth' \
--custom_output='rgb_obs','depth_obs','likelihood_map' \
--num_clusters=10 \
--global_map_size=100,100,1 \
--window_scaler=1.0 \
--pfnet_load=./pfnetwork/checkpoints/pfnet_igibson_data/report/rs_rgbd/checkpoint_28_0.065/pfnet_checkpoint \
--use_plot=True \
--store_plot=True \
--seed=100 > nohup_test_rl_uniform.out &

June 23rd 2021
--------------
1. train from scratch for single sequence - to check anything works
2. plot the trajectories on obstacle map to verify how diverse trajectories are
3. cross check for original dataset
4. different learning rate

$ nohup python -u display_pfnet_data.py \
--root_dir=./run1 \
--pfnet_loadpath='' \
--tfrecordpath=./Rs_data \
--obs_mode='rgb-depth' \
--num_train_samples=500 \
--batch_size=1 \
--s_buffer_size=50 \
--init_particles_distr='gaussian' \
--init_particles_std '0.2' '0.523599' \
--particles_range=100 \
--num_particles=30 \
--transition_std '0.04' '0.0872665' \
--resample=false \
--alpha_resample_ratio=0.5 \
--global_map_size '100' '100' '1' \
--window_scaler=1.0 \
--config_file=./configs/locobot_pfnet_nav.yaml \
--device_idx=0 \
--seed=42 > nohup.out &

June 30th 2021
--------------
1. interactively check trained pfnet performance in real-time
2. check for over-fitting for train data
3. k-means representation of particles for rl agent training
4. reproduce pfnet paper results for RGB-D then proceed to igibson


valid.tfrecords: 830 records
test.tfrecords: 820 records
train.tfrecords: 74800 records

$ nohup python -u train.py \
--logpath='rgb_depth' \
--trainfiles './house3d_data/train/train-001.tfrecords' \
--evalfiles './house3d_data/eval/valid.tfrecords' \
--num_train_samples=7500 \
--num_eval_samples=816 \
--obs_mode='rgb-depth' \
--init_particles_distr='tracking' \
--init_particles_std '0.15' '0.523599' \
--trajlen=24 \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--batch_size=6 \
--learning_rate=1e-4 \
--epochs=100 \
--gpu_num=1 \
--seed=42 > rgb_depth.out &

$ nohup python -u display_data.py \
--testfiles './house3d_data/eval/valid.tfrecords' \
--obs_mode='rgb-depth' \
--init_particles_distr='tracking' \
--init_particles_std '0.15' '0.523599' \
--trajlen=24 \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--batch_size=8 \
--gpu_num=0 \
--seed=42 > nohup.out &

$ nohup python -u test.py \
--logpath='rgb_depth' \
--testfiles './house3d_data/test/test.tfrecords' \
--num_test_samples=816 \
--obs_mode='rgb-depth' \
--load='' \
--init_particles_distr='tracking' \
--init_particles_std '0.15' '0.523599' \
--trajlen=24 \
--num_particles=30 \
--transition_std '0.' '0.' \
--resample=false \
--batch_size=6 \
--learning_rate=1e-4 \
--epochs=100 \
--gpu_num=1 \
--seed=42 > rgb_depth.out &

July 7th 2021
--------------
1. verify depth data for rgb+depth input
2. change following values
depth_low: 0.5
depth_high: 10.0
vertical_fov: 90
increase camera height in urdf file
3. use motion_planning to collect trajectory data

July 15th 2021
--------------
1. train single trajectory for > 1000 backprop steps(epoch) without noise
2. train for single apartment for > 1000 backprop steps(epoch) with and without noise

July 28th 2021
--------------
1. check if network doing well for train data
2. collect more training data
3. take the network trained on single aprt for rl task: rgbd + obstacle/floor map + k-mean (10 cluster) [x, y, theta, weight]
    1: at xy obstacle/empty
    2: at xy particle position particle weight (sum)
    3: at xy particle position orientation (weighted mean)

August 4th 2021
---------------
train rl with rgbd + particle cluster (in px) + floor_map + mse_reward - for fixed episode length (150 steps) single aprt
1. gaussian vs uniform initial dist
2. particle cluster use previous cluster centers as init guess vs random at each episode step.
3. raw particle + weights vs particle cluster
4. Active neural Localization and Deep Active Localization
5. AMCL vs pfnet with laser scan (optional)


August 10th 2021
----------------

other methods:
1. Differentiable Particle Filters (https://github.com/tu-rbo/differentiable-particle-filters)
2. differentiable_filters (https://github.com/akloss/differentiable_filters)
3. Semi-supervised Differentiable Particle Filters (https://github.com/HaoWen-Surrey/SemiDPF)

4. Active Neural Localization (https://github.com/devendrachaplot/Neural-Localization)
5. Deep Active Localization (https://github.com/montrealrobotics/dal)

1. per modality [rgb, depth, rgbd, lidar scan] to show same performance for igibson env as with paper's results.
  train particle filter net for ~100 apartments with multiple floors (i.e ~100k trajectories each 150 env steps)
  batch_size:4, gpu:12gb, ram:10gb, num_particles:50, train_epochs: 50 (per epoch use all data) -> 6 days training time + 1 day testing time (with ablation study)
  ablation: gaussion vs uniform init dist with multiple covariance, 500 vs 1000 particles, multiple re-sampling rate
  fine-tuning vs training from scratch vs out of box
2. train SAC rl agent with above filter for 1 apartment for reward(mse error + collision penality) obs(particle rep + floor map + rgbd)
  batch_size:4, gpu:6gb, ram:24gb, num_particles:500, train_epochs: 100k -> 3 days training time + testing time
  different representations: kmeans cluster center vs raw particles vs local floor map (particle centered)
  ablation: gaussion vs uniform init dist with multiple covariance, 500 vs 1000 particles, with and without rgbd obs, particle efficiency vs env step efficiency

  Deep active localization and Active neural localization implementation check


  August 11th 2021
  ----------------

1. log collisions
2. collision penality: -1.0
3. initialize uniform dist with offset to gt pose
4. 100 x 100 px from max range of lidar around robot
5. get tf1 working on pearl8

channel
1: at xy obstacle/empty (0/1)
2: at xy particle position particle weight (sum)
3: at xy particle position orientation (weighted mean)


Setup Instructions:
------------------
1. Install miniconda from (https://docs.conda.io/en/latest/miniconda.html)
2. Create conda environment
  $ conda create -n py3-igibson python=3.7 anaconda
  $ pip install --upgrade pip
  $ pip install tensorflow
3. Setup igibson from (http://svl.stanford.edu/igibson/docs/installation.html)
  $ git clone https://github.com/StanfordVL/iGibson --recursive --branch ig-develop
  $ cd iGibson
  $ source activate py3-igibson
  $ pip install -e .
4. add (lidar sensor) scan_link and scan_joint iGibson/igibson/data/assets/models/locobot/locobot.urdf
  refer turtlebot.urdf


  August 18th 2021
  ----------------
0. normalize reward instead of clip to [-10, 0]
1. use cos n sin for belief rep channel [4]
2. use different hyperparameters for sac (rl agent) with simplest task: fixed start position
    replay_buffer_capacity 1000
    train_steps_per_iteration 1
    batch_size 4
    gamma 0.99
    actor_learning_rate 0.0003
    critic_learning_rate 0.0003
    alpha_learning_rate 0.0003
2. use pixel wise/avg pool layer instead of square for likelihood_map
3. cross check if floormap/travmap can be generated online
4. start writing report/presentation


  August 25th 2021
  ----------------
1. ablation study
  a) fixed set of random init pose vs random init pose
  b) use gaussian init distribution
  b) different init covariance/transition std
  d) optional --actor_learning_rate=1e-05
2. implementing deep neural localization paper -> scan matching
3. start writing report/presentation

  September 1st 2021
  ------------------
1. log position, orientation, collision errors for training, evaluation, testing
2. sac_agent.SacAgent cross check optimizer not updating weights
3. train pfnet for couple of apartments to check generalize.
4. email authors of active neural localization regarding their implementation.


  September 9th 2021
  ------------------
1. use same particle filter lower update frequency for rl agent ad used in training
2. ablation study: test with higher update frequency particle filter success rate
3. randomly select eval/test apartments for particle filter net
4. log the results to final report table

  September 15th 2021
  -------------------
1. compare rl agent with agent used to collect pfnet data
2. train rl agent for more env duration (say 50 update step) vs sample poses from smaller area
3. ablation study: test with higher update frequency particle filter success rate
4. log max return
5. look into iGibson cited papers for test/eval data they used.


September 21st 2021
-------------------
1. plot x.axis w.r.t # of batches
2. store images instead of screen recording
3. lidar check for different scene if obstacles are being detected.
3. further analyze generalization of particle filter -> passive localization
4. if the 4.0 box case with 50 eps duration fails, look for changing reward function -> active localization
5. if have time, train for floor map instead of obstacle map
